{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:50:54.152433Z",
     "start_time": "2024-04-13T03:50:52.495812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (0.10.28)\r\n",
      "Requirement already satisfied: python-dotenv in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.2.2)\r\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.11)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.28 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.10.28)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.7)\r\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.5)\r\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.9.48)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.15)\r\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.5)\r\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.5)\r\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.3)\r\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.16)\r\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.4)\r\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.17.0)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.0.29)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (3.9.3)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.6.4)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.3.1)\r\n",
      "Requirement already satisfied: httpx in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.27.0)\r\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.1.16)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (3.3)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (3.8.1)\r\n",
      "Requirement already satisfied: numpy in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (2.2.2)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (10.3.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (8.2.3)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.6.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (4.11.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.16.0)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\r\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\r\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\r\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\r\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.9.4)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\r\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.6.4)\r\n",
      "Requirement already satisfied: anyio in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (4.3.0)\r\n",
      "Requirement already satisfied: certifi in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (0.14.0)\r\n",
      "Requirement already satisfied: click in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.4.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index) (2023.12.25)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\r\n",
      "Requirement already satisfied: PyMuPDFb==1.24.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.2.1)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.21.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index) (24.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.16.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install llama-index python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:50:57.181869Z",
     "start_time": "2024-04-13T03:50:54.153741Z"
    }
   },
   "id": "f15507067de9375b",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "chinook database をサンプルデータとして利用する。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e11019b4ffbf88c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (0.1.15)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.24 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-llms-openai) (0.10.28)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.29)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.3)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.4)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.3.1)\r\n",
      "Requirement already satisfied: httpx in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.27.0)\r\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.1.16)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.8.1)\r\n",
      "Requirement already satisfied: numpy in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.17.0)\r\n",
      "Requirement already satisfied: pandas in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.2)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (10.3.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.2.3)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.11.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\r\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.6.4)\r\n",
      "Requirement already satisfied: anyio in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.3.0)\r\n",
      "Requirement already satisfied: certifi in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.14.0)\r\n",
      "Requirement already satisfied: click in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.12.25)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.21.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (24.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.16.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:50:58.262891Z",
     "start_time": "2024-04-13T03:50:57.182503Z"
    }
   },
   "id": "12aab5c9be23f9e9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  298k  100  298k    0     0   234k      0  0:00:01  0:00:01 --:--:--  234k\r\n",
      "curl: (6) Could not resolve host: .\r\n",
      "Archive:  ./chinook.zip\r\n",
      "  inflating: chinook.db              \r\n"
     ]
    }
   ],
   "source": [
    "!curl \"https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\" -O ./chinook.zip\n",
    "!unzip -o ./chinook.zip"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:50:59.816411Z",
     "start_time": "2024-04-13T03:50:58.264713Z"
    }
   },
   "id": "b2b5f12da0208128",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    column,\n",
    ")\n",
    "\n",
    "engine = create_engine(\"sqlite:///chinook.db\")\n",
    "sql_database = SQLDatabase(engine)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:50:59.849739Z",
     "start_time": "2024-04-13T03:50:59.817298Z"
    }
   },
   "id": "f7db2b4ac515f050",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "global callback manager をセットアップする。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3f400ce7b4e98e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "\n",
    "callback_manager = CallbackManager()\n",
    "Settings.callback_manager = callback_manager"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:50:59.851976Z",
     "start_time": "2024-04-13T03:50:59.850454Z"
    }
   },
   "id": "7f6e0b36ea22e4e4",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:50:59.861602Z",
     "start_time": "2024-04-13T03:50:59.852521Z"
    }
   },
   "id": "47d3cca20306d8b7",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "setup a simple text-to-SQL tool: given a query, translate text to SQL, execute against database, and get back a result."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f28bfb5d5b05a9c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"albums\", \"tracks\", \"artists\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    name=\"sql_tool\",\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:50:59.977367Z",
     "start_time": "2024-04-13T03:50:59.862071Z"
    }
   },
   "id": "881422f984b3f769",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "次に、クエリ パイプライン構文を使用して、単一ステップの ReAct パイプラインをセットアップします。 これは、次のことを行う複数の部分からなるプロセスです。\n",
    "\n",
    "1. エージェントの入力を取り込む\n",
    "2. LLM を使用して ReAct プロンプトを呼び出し、次のアクション/ツールを生成します (または応答を返します)。\n",
    "3. ツール/アクションが選択されている場合は、ツール パイプラインを呼び出してツールを実行し、応答を収集します。\n",
    "4. レスポンスが発生した場合はレスポンスを取得します。\n",
    "\n",
    "この全体を通じて、エージェント固有のさまざまなクエリ コンポーネントを使用します。 通常のクエリ パイプラインとは異なり、これらは QueryPipelineAgentWorker で使用されるクエリ パイプライン用に特別に設計されています。\n",
    "\n",
    "- AgentInputComponent は、エージェント入力 (タスク、状態ディクショナリ) をクエリ パイプラインの入力セットに変換できるようにします。\n",
    "- AgentFnComponent: 現在のタスク、状態、および任意の入力を取り込み、出力を返すことができる汎用プロセッサです。 このクックブックでは、ReAct プロンプトをフォーマットする関数コンポーネントを定義します。 ただし、これはどこにでも置くことができます。\n",
    "- [このノートブックでは使用されません] CustomAgentComponent: AgentFnComponent と同様に、_run_component を実装して、タスクと状態にアクセスできる独自のロジックを定義できます。 AgentFnComponent よりも冗長ですが、より柔軟です (たとえば、初期化変数を定義でき、コールバックは基本クラス内にあります)。\n",
    "AgentFnComponent および AgentInputComponent に渡される関数には、タスクと状態がエージェントから渡される入力であるため、入力変数としてタスクと状態を含める必要があることに注意してください。\n",
    "\n",
    "エージェント クエリ パイプラインの出力は Tuple[AgentChatResponse, bool] でなければならないことに注意してください。 これは以下でわかります。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a0bd192171de0e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline as QP\n",
    "\n",
    "qp = QP(verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:50:59.979361Z",
     "start_time": "2024-04-13T03:50:59.977955Z"
    }
   },
   "id": "da9f6b14e32776ef",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "ここでは、すべてのエージェント ステップの開始時に呼び出されるエージェント入力コンポーネントを定義します。 入力を渡すだけでなく、初期化/状態変更も行います。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b885d1f7e6e0162f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.agent.react.types import (\n",
    "    ActionReasoningStep,\n",
    "    ObservationReasoningStep,\n",
    "    ResponseReasoningStep\n",
    ")\n",
    "from llama_index.core.agent import Task, AgentChatResponse\n",
    "from llama_index.core.query_pipeline import (\n",
    "    AgentInputComponent,\n",
    "    AgentFnComponent,\n",
    "    CustomAgentComponent,\n",
    "    QueryComponent,\n",
    "    ToolRunnerComponent\n",
    ")\n",
    "from llama_index.core.llms import MessageRole\n",
    "from typing import Dict, Any, Optional, Tuple, List, cast\n",
    "\n",
    "\n",
    "## Agent Input Component\n",
    "## This is the component that produces agent inputs to the rest of the components can also put initialization logic here.\n",
    "def agent_input_fn(task: Task, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Agent input function.\n",
    "    \n",
    "    Returns:\n",
    "        A Dictionary of output keys and values. If you are specifying src_key when defining links between this component and other components, make sure the src_key matches the specified output_key.\n",
    "\n",
    "    \"\"\"\n",
    "    # initialize current_reasoning\n",
    "    if \"current_reasoning\" not in state:\n",
    "        state[\"current_reasoning\"] = []\n",
    "    reasoning_step = ObservationReasoningStep(observation=task.input)\n",
    "    state[\"current_reasoning\"].append(reasoning_step)\n",
    "    return {\"input\": task.input}\n",
    "\n",
    "\n",
    "agent_input_component = AgentInputComponent(fn=agent_input_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:00.014200Z",
     "start_time": "2024-04-13T03:50:59.981032Z"
    }
   },
   "id": "7d4c79f92464593a",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "ここでは、ReAct プロンプトを生成するエージェント コンポーネントを定義し、LLM から出力が生成された後、構造化オブジェクトに解析します。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a55d8e224981ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActChatFormatter\n",
    "from llama_index.core.query_pipeline import InputComponent, Link\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool\n",
    "\n",
    "\n",
    "## define prompt function\n",
    "def react_prompt_fn(\n",
    "    task: Task, state: Dict[str, Any], input: str, tools: List[BaseTool]\n",
    ") -> List[ChatMessage]:\n",
    "    # Add input to reasoning\n",
    "    chat_formatter = ReActChatFormatter()\n",
    "    return chat_formatter.format(\n",
    "        tools,\n",
    "        chat_history=task.memory.get() + state[\"memory\"].get_all(),\n",
    "        current_reasoning=state[\"current_reasoning\"]\n",
    "    )\n",
    "\n",
    "react_prompt_component = AgentFnComponent(\n",
    "    fn=react_prompt_fn, partial_dict={\"tools\": [sql_tool]}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:00.016801Z",
     "start_time": "2024-04-13T03:51:00.014740Z"
    }
   },
   "id": "81bb059afc5341b",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: sql_tool\n",
      "Tool Description: Useful for translating a natural language query into a SQL query\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of sql_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "assistant: \n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.base.llms.generic_utils import messages_to_prompt\n",
    "\n",
    "chat_formatter = ReActChatFormatter()\n",
    "msgs = chat_formatter.format(\n",
    "    [sql_tool],\n",
    "    chat_history=[],\n",
    "    current_reasoning=[]\n",
    ")\n",
    "print(messages_to_prompt(msgs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:00.019653Z",
     "start_time": "2024-04-13T03:51:00.017330Z"
    }
   },
   "id": "5809f5ea63e728c4",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "LLM が出力を与えると、決定木が得られます。\n",
    "\n",
    "1. 答えが得られれば、それで終わりです。 出力を処理する\n",
    "2. アクションが指定されている場合は、指定された引数を使用して指定されたツールを実行し、出力を処理する必要があります。\n",
    "\n",
    "ツールの呼び出しは、ToolRunnerComponent モジュールを介して実行できます。 これはツールのリストを取り込む単純なラッパー モジュールで、指定されたツール名 (すべてのツールには名前があります) とツール アクションで「実行」できます。\n",
    "\n",
    "CustomAgentComponent をサブクラス化するこの全体的なモジュール OutputAgentComponent を実装します。\n",
    "\n",
    "注: また、高レベルのコールバック マネージャーを介してツール ランナー サブモジュールに渡すために、sub_query_components も実装します。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c99c1b55c58782c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import Set, Optional\n",
    "from llama_index.core.agent.react.output_parser import ReActOutputParser\n",
    "from llama_index.core.llms import ChatResponse\n",
    "from llama_index.core.agent.types import Task\n",
    "\n",
    "def parse_react_output_fn(\n",
    "        task: Task, state: Dict[str, Any], chat_response: ChatResponse\n",
    "):\n",
    "    \"\"\"Parse ReAct output into a reasoning step.\"\"\"\n",
    "    output_parser = ReActOutputParser()\n",
    "    reasoning_step = output_parser.parse(chat_response.message.content)\n",
    "    return {\"done\": reasoning_step.is_done, \"reasoning_step\": reasoning_step}\n",
    "\n",
    "parse_react_output = AgentFnComponent(fn=parse_react_output_fn)\n",
    "\n",
    "def run_tool_fn(\n",
    "        task: Task, state: Dict[str, Any], reasoning_step: ActionReasoningStep\n",
    "):\n",
    "    \"\"\"Run tool and process tool output.\"\"\"\n",
    "    tool_runner_component = ToolRunnerComponent(\n",
    "        [sql_tool],\n",
    "        callback_manager=task.callback_manager\n",
    "    )\n",
    "    tool_output = tool_runner_component.run_component(\n",
    "        tool_name=reasoning_step.action,\n",
    "        tool_input=reasoning_step.action_input\n",
    "    )\n",
    "    observation_step = ObservationReasoningStep(observation=str(tool_output))\n",
    "    state[\"current_reasoning\"].append(observation_step)\n",
    "    \n",
    "    return {\"response_str\": observation_step.get_content(), \"is_done\": False}\n",
    "    \n",
    "run_tool = AgentFnComponent(fn=run_tool_fn)\n",
    "\n",
    "def process_response_fn(\n",
    "        task: Task, state: Dict[str, Any], response_step: ResponseReasoningStep\n",
    "):\n",
    "    \"\"\"Process response.\"\"\"\n",
    "    state[\"current_reasoning\"].append(response_step)\n",
    "    response_str = response_step.response\n",
    "    # Now that we are done with this step, put into memory\n",
    "    state[\"memory\"].put(\n",
    "        ChatMessage(\n",
    "            content=task.input,\n",
    "            role=MessageRole.USER\n",
    "    ))\n",
    "    state[\"memory\"].put(\n",
    "        ChatMessage(\n",
    "            content=response_str,\n",
    "            role=MessageRole.ASSISTANT\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return {\"response_str\": response_str, \"is_done\": True}\n",
    "\n",
    "process_response = AgentFnComponent(fn=process_response_fn)\n",
    "\n",
    "def process_agent_response_fn(\n",
    "        task: Task, state: Dict[str, Any], response_dict: dict\n",
    "):\n",
    "    \"\"\"Process agent response.\"\"\"\n",
    "    return (\n",
    "        AgentChatResponse(response_dict[\"response_str\"]),\n",
    "        response_dict[\"is_done\"]\n",
    "    )\n",
    "    \n",
    "process_agent_response = AgentFnComponent(fn=process_agent_response_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:00.023510Z",
     "start_time": "2024-04-13T03:51:00.020210Z"
    }
   },
   "id": "5d2692f41dbde4a4",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "これで、最上位のエージェント パイプライン (agent_input -> accept_prompt -> llm -> accept_output) をつなぎ合わせることができます。\n",
    "\n",
    "最後のコンポーネントは、サブコンポーネントを呼び出す if-else コンポーネントです。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f422072ab470ba95"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "qp.add_modules(\n",
    "    {\n",
    "        \"agent_input\": agent_input_component,\n",
    "        \"react_prompt\": react_prompt_component,\n",
    "        \"llm\": OpenAI(model=os.getenv(\"CHAT_MODEL_GPT4\")),\n",
    "        \"react_output_parser\": parse_react_output,\n",
    "        \"run_tool\": run_tool,\n",
    "        \"process_response\": process_response,\n",
    "        \"process_agent_response\": process_agent_response,\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:00.026234Z",
     "start_time": "2024-04-13T03:51:00.023946Z"
    }
   },
   "id": "290757b3cfdef2f0",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Link input to react prompt to parsed out response (either tool action/input or observation)\n",
    "qp.add_chain(\n",
    "    [\"agent_input\", \"react_prompt\", \"llm\", \"react_output_parser\"]\n",
    ")\n",
    "\n",
    "# Add conditional link from react output to tool call (if not done)\n",
    "# ReActの結果、Tool呼び出しがある場合\n",
    "qp.add_link(\n",
    "    \"react_output_parser\",\n",
    "    \"run_tool\",\n",
    "    condition_fn=lambda x: not x[\"done\"],\n",
    "    input_fn=lambda x: x[\"reasoning_step\"]\n",
    ")\n",
    "\n",
    "# Add conditional link from react output to final response processing (if done)\n",
    "# ReActの結果、終了の場合\n",
    "qp.add_link(\n",
    "    \"react_output_parser\",\n",
    "    \"process_response\",\n",
    "    condition_fn=lambda x: x[\"done\"],\n",
    "    input_fn=lambda x: x[\"reasoning_step\"]\n",
    ")\n",
    "\n",
    "# Whether response processing or tool output processing, add link to final agent response\n",
    "qp.add_link(\"process_response\", \"process_agent_response\")\n",
    "qp.add_link(\"run_tool\", \"process_agent_response\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:00.029703Z",
     "start_time": "2024-04-13T03:51:00.026829Z"
    }
   },
   "id": "567bf628a6a44fb8",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_dag.html\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x146496a80>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"600px\"\n            src=\"agent_dag.html\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(\n",
    "    notebook=True,\n",
    "    cdn_resources=\"in_line\",\n",
    "    directed=True\n",
    ")\n",
    "net.from_nx(qp.clean_dag)\n",
    "net.show(\"agent_dag.html\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:00.123121Z",
     "start_time": "2024-04-13T03:51:00.030286Z"
    }
   },
   "id": "c1914bd248736c2c",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "これは、テキストから SQL へのクエリ パイプラインを中心にエージェントをセットアップする方法です。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86dcfae2c62df6af"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.agent import QueryPipelineAgentWorker, AgentRunner\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "\n",
    "agent_worker = QueryPipelineAgentWorker(qp)\n",
    "agent = AgentRunner(\n",
    "    agent_worker=agent_worker,\n",
    "    callback_manager=CallbackManager([]),\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:00.238486Z",
     "start_time": "2024-04-13T03:51:00.123774Z"
    }
   },
   "id": "3595472ccaacd80b",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agentを動かす"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "452c0f0ed56e5dcb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Start task\n",
    "task = agent.create_task(\n",
    "    \"What are some tracks from the artist AC/DC? Limit it to 3.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:00.243729Z",
     "start_time": "2024-04-13T03:51:00.241187Z"
    }
   },
   "id": "f346a4cea1d8c164",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 328a8222-b2a9-46f0-b360-89acb067f87f. Step input: What are some tracks from the artist AC/DC? Limit it to 3.\n",
      "\u001B[1;3;38;2;155;135;227m> Running module agent_input with input: \n",
      "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n",
      "task: task_id='f67dd681-1f91-40f7-acf2-0805b12109e5' input='What are some tracks from the artist AC/DC? Limit it to 3.' memory=ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module react_prompt with input: \n",
      "input: What are some tracks from the artist AC/DC? Limit it to 3.\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\\n\\n## Tools\\n\\n...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module react_output_parser with input: \n",
      "chat_response: assistant: Thought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
      "Action: sql_tool\n",
      "Action Input: {\"input\": \"List three tracks from the artist AC/DC\"...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module run_tool with input: \n",
      "reasoning_step: thought='The current language of the user is English. I need to use a tool to help me answer the question.' action='sql_tool' action_input={'input': 'List three tracks from the artist AC/DC'}\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module process_agent_response with input: \n",
      "response_dict: {'response_str': 'Observation: {\\'output\\': ToolOutput(content=\\'Three tracks from the artist AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let\\\\\\'s Get It Up\".\\',...\n",
      "\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:51:05.609979Z",
     "start_time": "2024-04-13T03:51:00.245557Z"
    }
   },
   "id": "f147fc3f4311cd23",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_output.is_last"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:54:52.635635Z",
     "start_time": "2024-04-13T03:54:52.629161Z"
    }
   },
   "id": "66382e2ff22ab662",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ad4528eee5dcbb0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three tracks from the artist AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let's Get It Up\".\n"
     ]
    }
   ],
   "source": [
    "print(step_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T04:08:26.037518Z",
     "start_time": "2024-04-13T04:08:26.035581Z"
    }
   },
   "id": "c4b19522a87aca94",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 2be3f540-66b2-4273-97de-bb95bbb0e93e. Step input: None\n",
      "\u001B[1;3;38;2;155;135;227m> Running module agent_input with input: \n",
      "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n",
      "task: task_id='f67dd681-1f91-40f7-acf2-0805b12109e5' input='What are some tracks from the artist AC/DC? Limit it to 3.' memory=ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module react_prompt with input: \n",
      "input: What are some tracks from the artist AC/DC? Limit it to 3.\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\\n\\n## Tools\\n\\n...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module react_output_parser with input: \n",
      "chat_response: assistant: Thought: The user has repeated the question, possibly due to not seeing the previous response. I can provide the answer directly now.\n",
      "\n",
      "Answer: Three tracks from the artist AC/DC are \"For Th...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module process_response with input: \n",
      "response_step: thought='The user has repeated the question, possibly due to not seeing the previous response. I can provide the answer directly now.' response='Three tracks from the artist AC/DC are \"For Those About...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module process_agent_response with input: \n",
      "response_dict: {'response_str': 'Three tracks from the artist AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let\\'s Get It Up\".', 'is_done': True}\n",
      "\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:55:31.870186Z",
     "start_time": "2024-04-13T03:55:27.791027Z"
    }
   },
   "id": "599a9aab03a7c052",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_output.is_last"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:57:08.047618Z",
     "start_time": "2024-04-13T03:57:08.042479Z"
    }
   },
   "id": "6326600a68a72703",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = agent.finalize_response(task.task_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:58:24.889157Z",
     "start_time": "2024-04-13T03:58:24.886234Z"
    }
   },
   "id": "ade981f498fe77f9",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three tracks from the artist AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let's Get It Up\".\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:58:31.379036Z",
     "start_time": "2024-04-13T03:58:31.375966Z"
    }
   },
   "id": "6f94b901b015f74d",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 6e530307-88d7-407d-9234-5886dca847cf. Step input: What are some tracks from the artist AC/DC? Limit it to 3.\n",
      "\u001B[1;3;38;2;155;135;227m> Running module agent_input with input: \n",
      "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n",
      "task: task_id='614e2fa9-823b-4891-b5a7-fdfe38134a95' input='What are some tracks from the artist AC/DC? Limit it to 3.' memory=ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module react_prompt with input: \n",
      "input: What are some tracks from the artist AC/DC? Limit it to 3.\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\\n\\n## Tools\\n\\n...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module react_output_parser with input: \n",
      "chat_response: assistant: Thought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
      "Action: sql_tool\n",
      "Action Input: {\"input\": \"List three tracks from the artist AC/DC\"...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module run_tool with input: \n",
      "reasoning_step: thought='The current language of the user is English. I need to use a tool to help me answer the question.' action='sql_tool' action_input={'input': 'List three tracks from the artist AC/DC'}\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module process_agent_response with input: \n",
      "response_dict: {'response_str': 'Observation: {\\'output\\': ToolOutput(content=\\'Three tracks from the artist AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let\\\\\\'s Get It Up\".\\',...\n",
      "\n",
      "\u001B[0m> Running step ed41882a-0a6c-4d6e-98ff-0934a955293c. Step input: None\n",
      "\u001B[1;3;38;2;155;135;227m> Running module agent_input with input: \n",
      "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n",
      "task: task_id='614e2fa9-823b-4891-b5a7-fdfe38134a95' input='What are some tracks from the artist AC/DC? Limit it to 3.' memory=ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module react_prompt with input: \n",
      "input: What are some tracks from the artist AC/DC? Limit it to 3.\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\\n\\n## Tools\\n\\n...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module react_output_parser with input: \n",
      "chat_response: assistant: Thought: The user has repeated the question, possibly due to not seeing the previous response. I will provide the answer again using the information from the previous tool output.\n",
      "\n",
      "Answer: ...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module process_response with input: \n",
      "response_step: thought='The user has repeated the question, possibly due to not seeing the previous response. I will provide the answer again using the information from the previous tool output.' response='Three tra...\n",
      "\n",
      "\u001B[0m\u001B[1;3;38;2;155;135;227m> Running module process_agent_response with input: \n",
      "response_dict: {'response_str': 'Three tracks from the artist AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let\\'s Get It Up\".', 'is_done': True}\n",
      "\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "# Run this e2e\n",
    "agent.reset()\n",
    "response = agent.chat(\n",
    "    \"What are some tracks from the artist AC/DC? Limit it to 3.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T03:59:21.551245Z",
     "start_time": "2024-04-13T03:59:12.320999Z"
    }
   },
   "id": "ddc17f5f8f657b2f",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three tracks from the artist AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let's Get It Up\".\n"
     ]
    }
   ],
   "source": [
    "print(step_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T04:08:03.192331Z",
     "start_time": "2024-04-13T04:08:03.187976Z"
    }
   },
   "id": "dc77dd5b41bd34cd",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8ebe2c8477f40b02"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
