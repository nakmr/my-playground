{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:25:32.469994Z",
     "start_time": "2024-04-11T12:25:30.975292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (0.10.28)\r\n",
      "Requirement already satisfied: python-dotenv in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.2.2)\r\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.11)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.28 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.10.28)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.7)\r\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.5)\r\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.9.48)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.15)\r\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.5)\r\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.5)\r\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.3)\r\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.16)\r\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index) (0.1.4)\r\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.17.0)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.0.29)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (3.9.3)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.6.4)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.3.1)\r\n",
      "Requirement already satisfied: httpx in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.27.0)\r\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.1.16)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (3.3)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (3.8.1)\r\n",
      "Requirement already satisfied: numpy in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (2.2.2)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (10.3.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (8.2.3)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.6.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (4.11.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.16.0)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\r\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\r\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\r\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\r\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.9.4)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\r\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.6.4)\r\n",
      "Requirement already satisfied: anyio in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (4.3.0)\r\n",
      "Requirement already satisfied: certifi in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (0.14.0)\r\n",
      "Requirement already satisfied: click in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.4.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index) (2023.12.25)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\r\n",
      "Requirement already satisfied: PyMuPDFb==1.24.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.2.1)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.21.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index) (24.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.16.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:07:26.884968Z",
     "start_time": "2024-04-11T12:07:18.206084Z"
    }
   },
   "id": "f15507067de9375b",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "chinook database をサンプルデータとして利用する。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e11019b4ffbf88c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (0.1.15)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.24 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-llms-openai) (0.10.28)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.29)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.3)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.4)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.3.1)\r\n",
      "Requirement already satisfied: httpx in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.27.0)\r\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.1.16)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.8.1)\r\n",
      "Requirement already satisfied: numpy in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.17.0)\r\n",
      "Requirement already satisfied: pandas in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.2)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (10.3.0)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.2.3)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.11.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\r\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.6.4)\r\n",
      "Requirement already satisfied: anyio in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.3.0)\r\n",
      "Requirement already satisfied: certifi in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.14.0)\r\n",
      "Requirement already satisfied: click in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.12.25)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.21.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (24.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.16.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/nakimura/Library/Caches/pypoetry/virtualenvs/llamaindex-lJi5NvAe-py3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:08:47.227383Z",
     "start_time": "2024-04-11T12:08:45.857920Z"
    }
   },
   "id": "12aab5c9be23f9e9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  298k  100  298k    0     0   419k      0 --:--:-- --:--:-- --:--:--  420k\r\n",
      "curl: (6) Could not resolve host: .\r\n",
      "Archive:  ./chinook.zip\r\n",
      "  inflating: chinook.db              \r\n"
     ]
    }
   ],
   "source": [
    "!curl \"https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\" -O ./chinook.zip\n",
    "!unzip -o ./chinook.zip"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:09:11.902116Z",
     "start_time": "2024-04-11T12:09:10.881920Z"
    }
   },
   "id": "b2b5f12da0208128",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    column,\n",
    ")\n",
    "\n",
    "engine = create_engine(\"sqlite:///chinook.db\")\n",
    "sql_database = SQLDatabase(engine)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:09:36.600432Z",
     "start_time": "2024-04-11T12:09:36.556857Z"
    }
   },
   "id": "f7db2b4ac515f050",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "global callback manager をセットアップする。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3f400ce7b4e98e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "\n",
    "callback_manager = CallbackManager()\n",
    "Settings.callback_manager = callback_manager"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:10:36.759706Z",
     "start_time": "2024-04-11T12:10:36.754630Z"
    }
   },
   "id": "7f6e0b36ea22e4e4",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:25:46.467306Z",
     "start_time": "2024-04-11T12:25:46.452601Z"
    }
   },
   "id": "47d3cca20306d8b7",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "setup a simple text-to-SQL tool: given a query, translate text to SQL, execute against database, and get back a result."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f28bfb5d5b05a9c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"albums\", \"tracks\", \"artists\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    name=\"sql_tool\",\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:25:54.255050Z",
     "start_time": "2024-04-11T12:25:54.247697Z"
    }
   },
   "id": "881422f984b3f769",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "次に、クエリ パイプライン構文を使用して、単一ステップの ReAct パイプラインをセットアップします。 これは、次のことを行う複数の部分からなるプロセスです。\n",
    "\n",
    "1. エージェントの入力を取り込む\n",
    "2. LLM を使用して ReAct プロンプトを呼び出し、次のアクション/ツールを生成します (または応答を返します)。\n",
    "3. ツール/アクションが選択されている場合は、ツール パイプラインを呼び出してツールを実行し、応答を収集します。\n",
    "4. レスポンスが発生した場合はレスポンスを取得します。\n",
    "\n",
    "この全体を通じて、エージェント固有のさまざまなクエリ コンポーネントを使用します。 通常のクエリ パイプラインとは異なり、これらは QueryPipelineAgentWorker で使用されるクエリ パイプライン用に特別に設計されています。\n",
    "\n",
    "- AgentInputComponent は、エージェント入力 (タスク、状態ディクショナリ) をクエリ パイプラインの入力セットに変換できるようにします。\n",
    "- AgentFnComponent: 現在のタスク、状態、および任意の入力を取り込み、出力を返すことができる汎用プロセッサです。 このクックブックでは、ReAct プロンプトをフォーマットする関数コンポーネントを定義します。 ただし、これはどこにでも置くことができます。\n",
    "- [このノートブックでは使用されません] CustomAgentComponent: AgentFnComponent と同様に、_run_component を実装して、タスクと状態にアクセスできる独自のロジックを定義できます。 AgentFnComponent よりも冗長ですが、より柔軟です (たとえば、初期化変数を定義でき、コールバックは基本クラス内にあります)。\n",
    "AgentFnComponent および AgentInputComponent に渡される関数には、タスクと状態がエージェントから渡される入力であるため、入力変数としてタスクと状態を含める必要があることに注意してください。\n",
    "\n",
    "エージェント クエリ パイプラインの出力は Tuple[AgentChatResponse, bool] でなければならないことに注意してください。 これは以下でわかります。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a0bd192171de0e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline as QP\n",
    "\n",
    "qp = QP(verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:28:55.909911Z",
     "start_time": "2024-04-11T12:28:55.904397Z"
    }
   },
   "id": "da9f6b14e32776ef",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "ここでは、すべてのエージェント ステップの開始時に呼び出されるエージェント入力コンポーネントを定義します。 入力を渡すだけでなく、初期化/状態変更も行います。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b885d1f7e6e0162f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.agent.react.types import (\n",
    "    ActionReasoningStep,\n",
    "    ObservationReasoningStep,\n",
    "    ResponseReasoningStep\n",
    ")\n",
    "from llama_index.core.agent import Task, AgentChatResponse\n",
    "from llama_index.core.query_pipeline import (\n",
    "    AgentInputComponent,\n",
    "    AgentFnComponent,\n",
    "    CustomAgentComponent,\n",
    "    QueryComponent,\n",
    "    ToolRunnerComponent\n",
    ")\n",
    "from llama_index.core.llms import MessageRole\n",
    "from typing import Dict, Any, Optional, Tuple, List, cast\n",
    "\n",
    "\n",
    "## Agent Input Component\n",
    "## This is the component that produces agent inputs to the rest of the components can also put initialization logic here.\n",
    "def agent_input_fn(task: Task, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Agent input function.\n",
    "    \n",
    "    Returns:\n",
    "        A Dictionary of output keys and values. If you are specifying src_key when defining links between this component and other components, make sure the src_key matches the specified output_key.\n",
    "\n",
    "    \"\"\"\n",
    "    # initialize current_reasoning\n",
    "    if \"current_reasoning\" not in state:\n",
    "        state[\"current_reasoning\"] = []\n",
    "    reasoning_step = ObservationReasoningStep(observation=task.input)\n",
    "    state[\"current_reasoning\"].qppend(reasoning_step)\n",
    "    return {\"input\": task.input}\n",
    "\n",
    "\n",
    "agent_input_component = AgentInputComponent(fn=agent_input_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:39:53.127719Z",
     "start_time": "2024-04-11T12:39:53.079723Z"
    }
   },
   "id": "7d4c79f92464593a",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "ここでは、ReAct プロンプトを生成するエージェント コンポーネントを定義し、LLM から出力が生成された後、構造化オブジェクトに解析します。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a55d8e224981ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActChatFormatter\n",
    "from llama_index.core.query_pipeline import InputComponent, Link\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool\n",
    "\n",
    "\n",
    "## define prompt function\n",
    "def react_prompt_fn(\n",
    "    task: Task, state: Dict[str, Any], input: str, tools: List[BaseTool]\n",
    ") -> List[ChatMessage]:\n",
    "    # Add input to reasoning\n",
    "    chat_formatter = ReActChatFormatter()\n",
    "    return chat_formatter.format(\n",
    "        tools,\n",
    "        chat_history=task.memory.get() + state[\"memory\"].get_all(),\n",
    "        current_reasoning=state[\"current_reasoning\"]\n",
    "    )\n",
    "\n",
    "react_prompt_component = AgentFnComponent(\n",
    "    fn=react_prompt_fn, partial_dict={\"tools\": [sql_tool]}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:51:53.973164Z",
     "start_time": "2024-04-11T12:51:53.966591Z"
    }
   },
   "id": "81bb059afc5341b",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: sql_tool\n",
      "Tool Description: Useful for translating a natural language query into a SQL query\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of sql_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "assistant: \n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.base.llms.generic_utils import messages_to_prompt\n",
    "\n",
    "chat_formatter = ReActChatFormatter()\n",
    "msgs = chat_formatter.format(\n",
    "    [sql_tool],\n",
    "    chat_history=[],\n",
    "    current_reasoning=[]\n",
    ")\n",
    "print(messages_to_prompt(msgs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T12:58:45.599593Z",
     "start_time": "2024-04-11T12:58:45.593701Z"
    }
   },
   "id": "5809f5ea63e728c4",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "461c2dd7c34fb44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
